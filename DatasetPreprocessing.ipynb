{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "print(f\"Initial dataset shape: {df.shape}\")\n",
        "print(f\"Column names: {list(df.columns)}\")\n",
        "\n",
        "# 1. Check duplicates\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(f\"\\nNumber of duplicate rows: {duplicate_count}\")\n",
        "if duplicate_count > 0:\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    print(f\"Dataset shape after removing duplicates: {df.shape}\")\n",
        "\n",
        "# 2. Check missing values\n",
        "missing_counts = df.isnull().sum()\n",
        "print(f\"\\nMissing values per column before any processing:\")\n",
        "for col, count in missing_counts.items():\n",
        "    if count > 0:\n",
        "        print(f\"  {col}: {count}\")\n",
        "if missing_counts.sum() == 0:\n",
        "    print(\"  No missing values found!\")\n",
        "\n",
        "# 3. Fill missing values (if any exist)\n",
        "\n",
        "# Define column types\n",
        "numeric_cols = ['recency', 'history']\n",
        "categorical_cols = ['zip_code', 'channel', 'offer']\n",
        "\n",
        "# Check if numeric columns exist and have missing values\n",
        "for col in numeric_cols:\n",
        "    if col in df.columns and df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "        print(f\"Filled missing values in {col} with median\")\n",
        "\n",
        "# Check if categorical columns exist and have missing values\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns and df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "        print(f\"Filled missing values in {col} with mode\")\n",
        "\n",
        "# Ensure numeric types for numeric columns\n",
        "for col in numeric_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "print(f\"\\nMissing values per column after filling:\")\n",
        "missing_after_fill = df.isnull().sum()\n",
        "for col, count in missing_after_fill.items():\n",
        "    if count > 0:\n",
        "        print(f\"  {col}: {count}\")\n",
        "if missing_after_fill.sum() == 0:\n",
        "    print(\"  No missing values!\")\n",
        "\n",
        "# 4. Create binary treatment variable\n",
        "if 'offer' in df.columns:\n",
        "    df['treatment'] = df['offer'].apply(lambda x: 0 if str(x).strip().lower() == 'no offer' else 1)\n",
        "    print(f\"\\nTreatment variable created:\")\n",
        "    print(f\"  Treatment=0 (No offer): {(df['treatment'] == 0).sum()}\")\n",
        "    print(f\"  Treatment=1 (Offer): {(df['treatment'] == 1).sum()}\")\n",
        "\n",
        "\n",
        "# 5. One-hot encode multi-category variables\n",
        "# Check which multi-category columns actually exist\n",
        "multi_cat_cols = [col for col in ['zip_code', 'channel'] if col in df.columns]\n",
        "\n",
        "if multi_cat_cols:\n",
        "    print(f\"\\nOne-hot encoding columns: {multi_cat_cols}\")\n",
        "\n",
        "    # Reset index to ensure proper alignment\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Create encoder and fit_transform\n",
        "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "    encoded_array = encoder.fit_transform(df[multi_cat_cols])\n",
        "\n",
        "    # Create DataFrame with proper index alignment\n",
        "    encoded_df = pd.DataFrame(\n",
        "        encoded_array,\n",
        "        columns=encoder.get_feature_names_out(multi_cat_cols),\n",
        "        index=df.index  # Ensure same index as original df\n",
        "    )\n",
        "\n",
        "    print(f\"  Encoded features shape: {encoded_df.shape}\")\n",
        "    print(f\"  Encoded feature names: {list(encoded_df.columns)}\")\n",
        "\n",
        "    # Concatenate with original df (excluding the original multi-category columns)\n",
        "    df_final = pd.concat([df.drop(columns=multi_cat_cols), encoded_df], axis=1)\n",
        "\n",
        "    print(f\"  Final dataset shape after encoding: {df_final.shape}\")\n",
        "else:\n",
        "    df_final = df.copy()\n",
        "    print(\"\\nNo multi-category columns found for one-hot encoding\")\n",
        "\n",
        "# Check for missing values after one-hot encoding\n",
        "missing_after_encoding = df_final.isnull().sum()\n",
        "print(f\"\\nMissing values per column after one-hot encoding:\")\n",
        "total_missing = 0\n",
        "for col, count in missing_after_encoding.items():\n",
        "    if count > 0:\n",
        "        print(f\"  {col}: {count}\")\n",
        "        total_missing += count\n",
        "\n",
        "if total_missing == 0:\n",
        "    print(\"  No missing values after one-hot encoding!\")\n",
        "else:\n",
        "    print(f\"\\nTotal missing values: {total_missing}\")\n",
        "\n",
        "    # Drop rows with any remaining missing values only if they exist\n",
        "    initial_rows = df_final.shape[0]\n",
        "    df_final.dropna(inplace=True)\n",
        "    rows_dropped = initial_rows - df_final.shape[0]\n",
        "    print(f\"Dropped {rows_dropped} rows with missing values after one-hot encoding.\")\n",
        "\n",
        "print(f\"\\nFinal dataset shape: {df_final.shape}\")\n",
        "\n",
        "# Logistic Regression Assumption Checks\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"LOGISTIC REGRESSION ASSUMPTION CHECKS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Prepare X and y\n",
        "y = df_final['conversion'] # Outcome variable\n",
        "X = df_final.drop(columns=['conversion', 'offer']) # Drop outcome and original 'offer'\n",
        "X_const = sm.add_constant(X) # Add intercept column\n",
        "\n",
        "\n",
        "# 1. Multicollinearity (VIF)\n",
        "\n",
        "print(f\"\\n1. MULTICOLLINEARITY CHECK (VIF)\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "try:\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"feature\"] = X_const.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]\n",
        "\n",
        "    print(\"Variance Inflation Factors (VIF):\")\n",
        "    for _, row in vif_data.iterrows():\n",
        "        status = \"⚠ High\" if row['VIF'] > 10 else \"✅ OK\"\n",
        "        print(f\"  {row['feature']}: {row['VIF']:.2f} {status}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error calculating VIF: {e}\")\n",
        "\n",
        "\n",
        "# 2. Linearity of logit for numeric predictors (Box-Tidwell)\n",
        "\n",
        "print(f\"\\n2. LINEARITY CHECK (Box-Tidwell)\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Only test numeric columns that actually exist\n",
        "existing_numeric_cols = [col for col in numeric_cols if col in X.columns]\n",
        "\n",
        "if existing_numeric_cols:\n",
        "    try:\n",
        "        df_bt = df_final.copy()\n",
        "        log_terms = []\n",
        "\n",
        "        for col in existing_numeric_cols:\n",
        "            # Add small constant to avoid log(0) and handle negative values\n",
        "            col_log = col + '_log'\n",
        "            df_bt[col_log] = df_bt[col] * np.log(df_bt[col] + abs(df_bt[col].min()) + 1)\n",
        "            log_terms.append(col_log)\n",
        "\n",
        "        # Create feature matrix for Box-Tidwell test\n",
        "        bt_features = existing_numeric_cols + log_terms\n",
        "        X_bt = sm.add_constant(df_bt[bt_features])\n",
        "\n",
        "        bt_test_model = sm.Logit(y, X_bt)\n",
        "        bt_result = bt_test_model.fit(disp=False)\n",
        "\n",
        "        print(\"Box-Tidwell test p-values (linearity check):\")\n",
        "        for feature, pval in bt_result.pvalues.items():\n",
        "            if feature in log_terms:\n",
        "                original_col = feature.replace('_log', '')\n",
        "                status = \"⚠ Non-linear\" if pval < 0.05 else \"✅ Linear\"\n",
        "                print(f\"  {original_col}: p={pval:.4f} {status}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Box-Tidwell test: {e}\")\n",
        "else:\n",
        "    print(\"No numeric predictors found for linearity testing.\")\n",
        "\n",
        "# 3. Large enough sample size (EPV rule)\n",
        "\n",
        "print(f\"\\n3. SAMPLE SIZE CHECK (EPV Rule)\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "num_events = y.sum()  # number of 1's (conversions)\n",
        "num_predictors = X_const.shape[1] - 1  # exclude intercept\n",
        "epv = num_events / num_predictors if num_predictors > 0 else 0\n",
        "\n",
        "print(f\"Number of events (conversions): {num_events}\")\n",
        "print(f\"Number of predictors: {num_predictors}\")\n",
        "print(f\"EPV (Events Per Variable): {epv:.2f}\")\n",
        "\n",
        "if epv < 10:\n",
        "    print(\"⚠ Warning: EPV < 10 → Model may be overfitted.\")\n",
        "else:\n",
        "    print(\"✅ EPV rule satisfied.\")\n",
        "\n",
        "# Save outputs\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(\"SAVING OUTPUTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    df_final.to_csv(\"preprocessed_dataset.csv\", index=False)\n",
        "    print(\"✅ Preprocessed dataset saved as 'preprocessed_dataset.csv'\")\n",
        "\n",
        "    if 'conversion' in df_final.columns:\n",
        "        X_const.to_csv(\"X_ready.csv\", index=False)\n",
        "        y.to_csv(\"y_ready.csv\", index=False, header=['conversion'])\n",
        "        print(\"✅ Feature matrix (X) saved as 'X_ready.csv'\")\n",
        "        print(\"✅ Target variable (y) saved as 'y_ready.csv'\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error saving files: {e}\")\n",
        "\n",
        "print(f\"\\n✅ Preprocessing and assumption checks complete!\")\n",
        "print(f\"Final dataset summary:\")\n",
        "print(f\"  Shape: {df_final.shape}\")\n",
        "print(f\"  Columns: {list(df_final.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsEMhz7Fzdvo",
        "outputId": "5914643a-b29d-432b-e02e-ebfa4681c7d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (64000, 9)\n",
            "Column names: ['recency', 'history', 'used_discount', 'used_bogo', 'zip_code', 'is_referral', 'channel', 'offer', 'conversion']\n",
            "\n",
            "Number of duplicate rows: 6603\n",
            "Dataset shape after removing duplicates: (57397, 9)\n",
            "\n",
            "Missing values per column before any processing:\n",
            "  No missing values found!\n",
            "\n",
            "Missing values per column after filling:\n",
            "  No missing values!\n",
            "\n",
            "Treatment variable created:\n",
            "  Treatment=0 (No offer): 19072\n",
            "  Treatment=1 (Offer): 38325\n",
            "\n",
            "One-hot encoding columns: ['zip_code', 'channel']\n",
            "  Encoded features shape: (57397, 4)\n",
            "  Encoded feature names: ['zip_code_Surburban', 'zip_code_Urban', 'channel_Phone', 'channel_Web']\n",
            "  Final dataset shape after encoding: (57397, 12)\n",
            "\n",
            "Missing values per column after one-hot encoding:\n",
            "  No missing values after one-hot encoding!\n",
            "\n",
            "Final dataset shape: (57397, 12)\n",
            "\n",
            "==================================================\n",
            "LOGISTIC REGRESSION ASSUMPTION CHECKS\n",
            "==================================================\n",
            "\n",
            "1. MULTICOLLINEARITY CHECK (VIF)\n",
            "----------------------------------------\n",
            "Variance Inflation Factors (VIF):\n",
            "  const: 36.36 ⚠ High\n",
            "  recency: 1.06 ✅ OK\n",
            "  history: 1.45 ✅ OK\n",
            "  used_discount: 3.13 ✅ OK\n",
            "  used_bogo: 3.13 ✅ OK\n",
            "  is_referral: 1.07 ✅ OK\n",
            "  treatment: 1.00 ✅ OK\n",
            "  zip_code_Surburban: 2.17 ✅ OK\n",
            "  zip_code_Urban: 2.17 ✅ OK\n",
            "  channel_Phone: 2.76 ✅ OK\n",
            "  channel_Web: 2.76 ✅ OK\n",
            "\n",
            "2. LINEARITY CHECK (Box-Tidwell)\n",
            "----------------------------------------\n",
            "Box-Tidwell test p-values (linearity check):\n",
            "  recency: p=0.0007 ⚠ Non-linear\n",
            "  history: p=0.0975 ✅ Linear\n",
            "\n",
            "3. SAMPLE SIZE CHECK (EPV Rule)\n",
            "----------------------------------------\n",
            "Number of events (conversions): 8961\n",
            "Number of predictors: 10\n",
            "EPV (Events Per Variable): 896.10\n",
            "✅ EPV rule satisfied.\n",
            "\n",
            "==================================================\n",
            "SAVING OUTPUTS\n",
            "==================================================\n",
            "✅ Preprocessed dataset saved as 'preprocessed_dataset.csv'\n",
            "✅ Feature matrix (X) saved as 'X_ready.csv'\n",
            "✅ Target variable (y) saved as 'y_ready.csv'\n",
            "\n",
            "✅ Preprocessing and assumption checks complete!\n",
            "Final dataset summary:\n",
            "  Shape: (57397, 12)\n",
            "  Columns: ['recency', 'history', 'used_discount', 'used_bogo', 'is_referral', 'offer', 'conversion', 'treatment', 'zip_code_Surburban', 'zip_code_Urban', 'channel_Phone', 'channel_Web']\n"
          ]
        }
      ]
    }
  ]
}